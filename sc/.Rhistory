HEAD(Data_PT)
head(Data_PT)
summarise(Data_PT)
Data_PT %>%
sum(Q71 == 'Female', na.rm = TRUE)
Data_PT$Q71 %>%
sum('Female', na.rm = TRUE)
?sum
?count
sum(Data_PT$Q71 == "Female", na.rm = TRUE)
sum(Data_PT$Q71 == 2, na.rm = TRUE)
sum(Data_PT$Q71 == 1, na.rm = TRUE)
sum(Data_PT$Q71 == 3, na.rm = TRUE)
sum(Data_PT$Q71 == 4, na.rm = TRUE)
female <- sum(Data_PT$Q71 == 2, na.rm = TRUE)
male <- sum(Data_PT$Q71 == 1, na.rm = TRUE)
No_say <- sum(Data_PT$Q71 == 4, na.rm = TRUE)
percentage <- female / (female + male + no_say)
percentage <- female / (female + male + No_say)
percentage
female <- sum(Data_PT$Q71 == 2, na.rm = TRUE)
male
female
age18_24 <- sum(Data_PT$Q70 == "18 - 24", na.rm = TRUE)
age18_24
age18_24 <- sum(Data_PT$Q70 == 1, na.rm = TRUE)
age18_24
age18_24 <- sum(Data_PT$Q70 == 2, na.rm = TRUE)
age18_24
age25_34 <- sum(Data_PT$Q70 == 3, na.rm = TRUE)
age25_34
sum(Data_PT$Q70 == 4, na.rm = TRUE)
sum(Data_PT$Q70 == 1:5, na.rm = TRUE)
sum(Data_PT$Q70 == 4, na.rm = TRUE)
sum(Data_PT$Q70 == 3, na.rm = TRUE)
sum(Data_PT$Q70 == 2, na.rm = TRUE)
sum(Data_PT$Q70 == 3, na.rm = TRUE)
sum(Data_PT$Q70 == 4, na.rm = TRUE)
sum(Data_PT$Q70 == 5, na.rm = TRUE)
install.packages('lavaan')
library(lavaan)
library(haven)
install.packages('psych')
library(psych)
describe(iris)
library(readr)
Thesis_MM_General_pop_April_17_2023_02_56 <- read_csv("Documents/MMMA/MM/Thesis/Analyze/Main/Thesis MM - General pop_April 17, 2023_02.56.csv")
View(Thesis_MM_General_pop_April_17_2023_02_56)
#load data
data <- read_csv("Documents/MMMA/MM/Thesis/Analyze/Main/Thesis MM - General pop_April 17, 2023_02.56.csv")
#clean data
data <- select(Data_PT, -(1:8))
library(lavaan)
library(psych)
library(readr)
library(tidyr)
library(dplyr)
#clean data
data <- select(Data_PT, -(1:8))
View(data)
-
#load data
data_M <- read_csv("Documents/MMMA/MM/Thesis/Analyze/Main/Thesis MM - General pop_April 17, 2023_02.56.csv")
#load data
data_M <- read_csv("Documents/MMMA/MM/Thesis/Analyze/Main/Thesis MM - General pop_April 17, 2023_02.56.csv")
View(data_M)
#clean data
data_M <- select(Data_PT, -(1:8))
#load data
data_M <- read_csv("Documents/MMMA/MM/Thesis/Analyze/Main/Thesis MM - General pop_April 17, 2023_02.56.csv")
#clean data
data_M <- select(Data_M, -(1:8))
#load data
data_M <- read_csv("Documents/MMMA/MM/Thesis/Analyze/Main/Thesis MM - General pop_April 17, 2023_02.56.csv")
#clean data
data_M <- select(data_M, -(1:8))
data <- select(data_M, -(2:21))
View(data)
data <-
data %>%
rowwise() %>%
mutate(Trust = mean(Q11_1, Q11_2, Q11_3, Q11_4))
#create composite scores
data <-
data %>%
rowwise() %>%
mutate(Trust = mean(c(Q11_1, Q11_2, Q11_3, Q11_4)))
#create composite scores
data <-
data %>%
rowwise() %>%
mutate(Trust = mean(c(Q11_1, Q11_2, Q11_3, Q11_4)))
class(data$Q11_1)
data <- data %>%
mutate_at(vars(-ResponseId), as.numeric)
data <-
data %>%
rowwise() %>%
mutate(Trust = mean(c(Q11_1, Q11_2, Q11_3, Q11_4)))
data <-
data %>%
rowwise() %>%
mutate(Trust = mean(c(Q11_1, Q11_2, Q11_3, Q11_4)))
data <-
data %>%
rowwise() %>%
mutate(Identification = mean(c(Q10_1, Q10_2, Q10_3, Q10_4, Q10_5, Q10_6)))
data <-
data %>%
rowwise() %>%
mutate(Commitment = mean(c(Q9_1, Q9_2, Q9_3, Q9_4, Q9_5)))
data <-
data %>%
rowwise() %>%
mutate(PE = mean(c(Q7_1, Q7_2, Q7_3, Q7_4, Q7_5)))
data <-
data %>%
rowwise() %>%
mutate(Intent = mean(c(Q8_1, Q8_2, Q8_3, Q8_4)))
model1 <- 'Commitment ~ Trust + Identification
Intent ~ Commitment
Intent ~ Commitment'
fit1 <- sem(model1, data = data)
model1 <- 'Commitment ~ Trust + Identification
Intent ~ Commitment'
fit1 <- sem(model1, data = data)
#confirmatory factor analisys
modelCFA <- 'Trust =~ Q11_1 + Q11_2 + Q11_3 + Q11_4
Identification =~ Q10_1 + Q10_2 + Q10_3 + Q10_4 + Q10_5 + Q10_6
Commitment =~ Q9_1 + Q9_2 + Q9_3 + Q9_4 + Q9_5
Perceived =~ Q7_1 + Q7_2 + Q7_3 + Q7_4 + Q7_5
Intent =~ Q8_1 + Q8_2 + Q8_3 + Q8_4'
modelCFA <- 'Trust =~ Q11_1 + Q11_2 + Q11_3 + Q11_4
Identification =~ Q10_1 + Q10_2 + Q10_3 + Q10_4 + Q10_5 + Q10_6
Commitment =~ Q9_1 + Q9_2 + Q9_3 + Q9_4 + Q9_5
Perceived =~ Q7_1 + Q7_2 + Q7_3 + Q7_4 + Q7_5
Intent =~ Q8_1 + Q8_2 + Q8_3 + Q8_4'
fit <- cfa(modelCFA, data = data)
#confirmatory factor analisys
modelCFA <- 'Trust_CFA =~ Q11_1 + Q11_2 + Q11_3 + Q11_4
Identification_CFA =~ Q10_1 + Q10_2 + Q10_3 + Q10_4 + Q10_5 + Q10_6
Commitment_CFA =~ Q9_1 + Q9_2 + Q9_3 + Q9_4 + Q9_5
Perceived_CFA =~ Q7_1 + Q7_2 + Q7_3 + Q7_4 + Q7_5
Intent_CFA =~ Q8_1 + Q8_2 + Q8_3 + Q8_4'
fit <- cfa(modelCFA, data = data)
modelCFA <- 'Trust_CFA =~ Q11_1 + Q11_2 + Q11_3 + Q11_4
Identification_CFA =~ Q10_1 + Q10_2 + Q10_3 + Q10_4 + Q10_5 + Q10_6
Commitment_CFA =~ Q9_1 + Q9_2 + Q9_3 + Q9_4 + Q9_5
Perceived_CFA =~ Q7_1 + Q7_2 + Q7_3 + Q7_4 + Q7_5
Intent_CFA =~ Q8_1 + Q8_2 + Q8_3 + Q8_4'
fit <- cfa(modelCFA, data = data)
fit
fit <- cfa(modelCFA, data = data)
summary(fit, fit.measures = TRUE, standardized = TRUE)
#load data
data_M <- read_csv("Documents/MMMA/MM/Thesis/Analyze/Main/Thesis MM - General pop_April 17, 2023_02.56.csv")
data_M <- select(data_M, -(1:8))
data <- select(data_M, -(2:21))
#make numeric scores
data <- data %>%
mutate_at(vars(-ResponseId, Q13, Q15, Q16), as.numeric)
class(data$Q13)
anova_model <- aov(Trust ~ Q13, data = data)
#create composite scores
data <-
data %>%
rowwise() %>%
mutate(Trust = mean(c(Q11_1, Q11_2, Q11_3, Q11_4)))
anova_model <- aov(Trust ~ Q13, data = data)
summary(anova_model)
dependent_vars <- c("Trust", "Identification", "Commitment")
# Use lapply to run ANOVAs for each dependent variable and store the results in a list
anova_list <- lapply(dependent_vars, function(var) {
aov_model <- aov(paste(var, " ~ gender"), data = df)
return(summary(aov_model))
})
boxplot(Trust ~ gender, data = data, xlab = "Gender", ylab = "Level of trust")
boxplot(Trust ~ Q13, data = data, xlab = "Gender", ylab = "Level of trust")
ggplot(data, aes(x = Trust, y = Q13)) +
geom_boxplot() +
facet_wrap(~gender, ncol = 1) +
ylab("Q13") +
xlab("Gender") +
ggtitle("Boxplot of Q13 by Gender")
library(ggplot2)
ggplot(data, aes(x = Trust, y = Q13)) +
geom_boxplot() +
facet_wrap(~gender, ncol = 1) +
ylab("Q13") +
xlab("Gender") +
ggtitle("Boxplot of Q13 by Gender")
ggplot(data, aes(x = Trust, y = Q13)) +
geom_boxplot() +
facet_wrap(~Q13, ncol = 1) +
ylab("Q13") +
xlab("Gender") +
ggtitle("Boxplot of Q13 by Gender")
data_M <- read_csv("Documents/MMMA/MM/Thesis/Analyze/Main/Thesis MM - General pop_April 17, 2023_02.56.csv")
#omit missing
data <- na.omit(data_M)
#load data
data_M <- read_csv("Documents/MMMA/MM/Thesis/Analyze/Main/Thesis MM - General pop_April 17, 2023_02.56.csv")
data <- select(data, -(1:8))
data <- select(data, -(2:21))
#load data
data_M <- read_csv("Documents/MMMA/MM/Thesis/Analyze/Main/Thesis MM - General pop_April 17, 2023_02.56.csv")
data <- select(data_M, -(1:8))
data <- select(data, -(2:21))
email <- select(data, Q12)
View(email)
data <- select(data, -Q12)
#omit missing
data <- na.omit(data_M)
#omit missing
data <- na.omit(data)
#load data
data_M <- read_csv("Documents/MMMA/MM/Thesis/Analyze/Main/Thesis MM - General pop_April 17, 2023_02.56.csv")
#delete columns
data <- select(data_M, -(1:8))
data <- select(data, -(2:21))
email <- select(data, Q12)
data <- select(data, -Q12)
#omit missing
data <- na.omit(data)
ggplot(data, aes(x = Trust, y = Q13)) +
geom_boxplot() +
facet_wrap(~Q13, ncol = 1) +
ylab("Q13") +
xlab("Gender") +
ggtitle("Boxplot of Q13 by Gender")
mediation_model <- 'Trust_MM =~ Q11_1 + Q11_2 + Q11_3 + Q11_4
Identification_MM =~ Q10_1 + Q10_2 + Q10_3 + Q10_4 + Q10_5 + Q10_6
Commitment_MM =~ Q9_1 + Q9_2 + Q9_3 + Q9_4 + Q9_5
Perceived_MM =~ Q7_1 + Q7_2 + Q7_3 + Q7_4 + Q7_5
Intent_MM =~ Q8_1 + Q8_2 + Q8_3 + Q8_4
Trust_MM ~ a*Status_MM
Identification_MM ~ b*Status_MM
Commitment_MM ~ c*Trust_MM
Commitment_MM ~ d*Identification_MM
Intent_MM ~ e*Commitment_MM
Perceived_MM ~ f*Status_MM
Intent_MM ~ g*Perceived_MM
Indirect1 := a + c + e
Indirect2 := b + d + e
'
fit_mediation <- sem(mediation_model, data = data, std.lv = T, se = 'boot', bootstrap = 100)
library(lavaan)
mediation_model <- 'Trust_MM =~ Q11_1 + Q11_2 + Q11_3 + Q11_4
Identification_MM =~ Q10_1 + Q10_2 + Q10_3 + Q10_4 + Q10_5 + Q10_6
Commitment_MM =~ Q9_1 + Q9_2 + Q9_3 + Q9_4 + Q9_5
Perceived_MM =~ Q7_1 + Q7_2 + Q7_3 + Q7_4 + Q7_5
Intent_MM =~ Q8_1 + Q8_2 + Q8_3 + Q8_4
Trust_MM ~ a*Status_MM
Identification_MM ~ b*Status_MM
Commitment_MM ~ c*Trust_MM
Commitment_MM ~ d*Identification_MM
Intent_MM ~ e*Commitment_MM
Perceived_MM ~ f*Status_MM
Intent_MM ~ g*Perceived_MM
Indirect1 := a + c + e
Indirect2 := b + d + e
'
fit_mediation <- sem(mediation_model, data = data, std.lv = T, se = 'boot', bootstrap = 100)
#load data
data_M <- read_csv("Documents/MMMA/MM/Thesis/Analyze/Main/Thesis MM - General pop_April 18, 2023_08.26.csv")
library(lavaan)
library(psych)
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
#load data
data_M <- read_csv("Documents/MMMA/MM/Thesis/Analyze/Main/Thesis MM - General pop_April 18, 2023_08.26.csv")
View(data_M)
MOF <- 9.21 - 4.5
EME <- 9.44 - 4.96
MOF > EME
162,84 + 31,99
162.84 + 31.99
162.84 + 31.99 + 10 + 65+ 8.2+ 7.5+ 21.64+ 55+40+142.90+ 75+20+11+23+4.8+18.49+62.95+10+22+127.20
geld <- 162.84 + 31.99 + 10 + 65+ 8.2+ 7.5+ 21.64+ 55+40+142.90+ 75+20+11+23+4.8+18.49+62.95+10+22+127.20
geld /2
geld <- 162.84 + 31.99 + 10 + 65+ 8.2+ 7.5+ 21.64+ 55+40+142.90+ 75+20+11+23+4.8+18.49+62.95+10+22+127.20 + 404.4
geld /2
install.packages("xgboost")
library(xgboost)
install.packages("modeldata")
library(modeldata)
data("stackoverflow")
force(stackoverflow)
View(stackoverflow)
library(dplyr)
y <- as.numeric(stackoverflow$Remote)
y <- as.numeric(stackoverflow$Remote) -1
x <- stackoverflow %>% select(-Remote)
#transform factor into a dummy
install.packages("fastDummies")
library(fastDummies)
x <- dummy_cols(x,
remove_first_dummy = TRUE)
View(x)
x <- x %>% select(-Country)
#setting the parameters
params <- list(set.seed = 1502,
eval_matric = 'auc',
objective = "binary:logistic")
#run XGBoost
install.packages("xgboost")
install.packages("xgboost")
#run XGBoost
library(xgboost)
model <- xgboost(data = as.matrix(x),
label = y,
params = params,
nrounds = 20,
verbose = 1
)
xgb.plot.shap(data = as.matrix(x),
model = model,
top_n = 5)
#from this plot we can classify the 5 most important drivers to see if someone is working remotely or not
xgb.plot.shap(data = as.matrix(x),
model = model,
top_n = 7)
data <- read.csv("~/Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv", nrows = 1000)
#spotify popularity distribution
ggplot(data, aes(x = spotify_popularity)) +
geom_histogram(binwidth = 1, fill = "blue", color = "black") +
labs(title = "Spotify Popularity Distribution", x = "Spotify Popularity", y = "Frequency")
library(dplyr)
library(ggplot2)
library(GGally)
#spotify popularity distribution
ggplot(data, aes(x = spotify_popularity)) +
geom_histogram(binwidth = 1, fill = "blue", color = "black") +
labs(title = "Spotify Popularity Distribution", x = "Spotify Popularity", y = "Frequency")
#Bar plot of Track Genres
ggplot(data, aes(x = track_genre)) +
geom_bar(fill = "blue") +
labs(title = "Track Genre Distribution", x = "Genre", y = "Count")
#Pair Plot
ggpairs(data[, c("spotify_popularity", "danceability", "energy", "acousticness", "genre_hiphop", "genre_classical")])
0.0128 * 1900000
unique_track_ids <- unique(data$track_id)
# Calculate the number of unique track IDs
num_unique_track_ids <- length(unique_track_ids)
num_unique_track_ids
data <- read.csv("~/Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv", nrows = 250000)
unique_track_ids <- unique(data$track_id)
# Calculate the number of unique track IDs
num_unique_track_ids <- length(unique_track_ids)
num_unique_track_ids
data <- read.csv("~/Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv")
unique_track_ids <- unique(data$track_id)
# Calculate the number of unique track IDs
num_unique_track_ids <- length(unique_track_ids)
num_unique_track_ids
library(readr)
data_long_prepped <- read_csv("Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv")
View(data_long_prepped)
class(data_long_prepped$n_playlist_inclusion)
max(data_long_prepped$n_playlist_inclusion)
min(data_long_prepped$n_playlist_inclusion)
mean(data_long_prepped$n_playlist_inclusion)
boxplot(data_long_prepped$n_playlist_inclusion, main="Boxplot of n_playlist_inclusion", ylab="Values")
# Boxplot without individual outlier points
boxplot(data_long_prepped$n_playlist_inclusion, main="Boxplot of n_playlist_inclusion", ylab="Values", outline=FALSE)
mean(data_long_prepped$spotify_popularity)
max(data_long_prepped$spotify_popularity)
min(data_long_prepped$spotify_popularity)
mean(data_long_prepped$sumfollowers)
min(data_long_prepped$sumfollowers)
max(data_long_prepped$sumfollowers)
median(data_long_prepped$n_playlist_inclusion)
modus(data_long_prepped$n_playlist_inclusion)
install.packages("XGBoost")
install.packages("xgboost")
install.packages("xgboost")
library(readr)
data_long_prepped <- read_csv("Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv")
View(data_long_prepped)
data <- read.csv("~/Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv", nrows = 500)
data <- as.data.frame(data)
data
# Iterate through all columns and replace empty cells with NA
data <- lapply(data, function(x) {
x[x == ""] <- NA
return(x)
})
#calculate the mean popularity of songs
result <- data %>%
filter(treated == "0") %>%
summarise(mean_popularity = mean(as.numeric(spotify_popularity), na.rm = TRUE))
library(tidyr)
library(dplyr)
library(tidyr)
library(dplyr)
data <- read.csv("~/Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv", nrows = 500)
data <- as.data.frame(data)
data
# Iterate through all columns and replace empty cells with NA
data <- lapply(data, function(x) {
x[x == ""] <- NA
return(x)
})
#calculate the mean popularity of songs
result <- data %>%
filter(treated == "0") %>%
summarise(mean_popularity = mean(as.numeric(spotify_popularity), na.rm = TRUE))
library(tidyr)
library(dplyr)
data <- read.csv("~/Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv", nrows = 500)
data <- as.data.frame(data)
data
# Iterate through all columns and replace empty cells with NA
data <- lapply(data, function(x) {
x[x == ""] <- NA
return(x)
})
#calculate the mean popularity of songs
result <- data %>%
filter(treated == "0") %>%
summarise(mean_popularity = mean(as.numeric(spotify_popularity), na.rm = TRUE))
# Load the required libraries
library(dplyr)
# Assuming 'data' is your dataset with columns $artist_names and $name
# Create a new data frame with unique artist names and their songs
unique_data <- data %>%
distinct(artist_names, name)
data <- read.csv("~/Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv", nrows = 500)
# Load the required libraries
library(dplyr)
# Assuming 'data' is your dataset with columns $artist_names and $name
# Create a new data frame with unique artist names and their songs
unique_data <- data %>%
distinct(artist_names, name)
# Write the data frame to a CSV file
write.csv(unique_data, file = "unique_artists_and_songs.csv", row.names = FALSE)
setwd("~/Documents/MMMA/MA/Thesis_23/ThesisMA/sc")
# Load the required libraries
library(dplyr)
# Assuming 'data' is your dataset with columns $artist_names and $name
# Create a new data frame with unique artist names and their songs
unique_data <- data %>%
distinct(artist_names, name)
# Write the data frame to a CSV file
write.csv(unique_data, file = "unique_artists_and_songs.csv", row.names = FALSE)
# Load the required libraries
library(dplyr)
# Assuming 'data' is your dataset with columns $artist_names and $name
# Create a new data frame with unique artist names and their songs
unique_data <- data %>%
distinct(artist_names, name)
# Write the data frame to a CSV file
write.csv(unique_data, file = "../Data/unique_artists_and_songs.csv", row.names = FALSE)
data <- read.csv("~/Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv", nrows = 100000)
# Load the required libraries
library(dplyr)
# Assuming 'data' is your dataset with columns $artist_names and $name
# Create a new data frame with unique artist names and their songs
unique_data <- data %>%
distinct(artist_names, name)
# Write the data frame to a CSV file
write.csv(unique_data, file = "../Data/unique_artists_and_songs.csv", row.names = FALSE)
data <- read.csv("~/Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv", nrows = 50000)
# Load the required libraries
library(dplyr)
# Assuming 'data' is your dataset with columns $artist_names and $name
# Create a new data frame with unique artist names and their songs
unique_data <- data %>%
distinct(artist_names, name)
# Write the data frame to a CSV file
write.csv(unique_data, file = "../Data/unique_artists_and_songs.csv", row.names = FALSE)
data <- read.csv("~/Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv", nrows = 25000)
# Load the required libraries
library(dplyr)
# Assuming 'data' is your dataset with columns $artist_names and $name
# Create a new data frame with unique artist names and their songs
unique_data <- data %>%
distinct(artist_names, name)
# Write the data frame to a CSV file
write.csv(unique_data, file = "../Data/unique_artists_and_songs.csv", row.names = FALSE)
lyrics <- read.csv("lyrics.csv")
not_found <- read.csv("songs_notfound.csv")
not_found <- read.csv("songs_not_found.csv")
len(lyrics)
rows(lyrics)
nrow(lyrics)
nrow(songs_not_found)
nrow(not_found)
nrow(unique_data)
nrow(lyrics)
nrow(not_found)
nrow(unique_data)
data <- read.csv("~/Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv", nrows = 200)
# Load the required libraries
library(dplyr)
# Assuming 'data' is your dataset with columns $artist_names and $name
# Create a new data frame with unique artist names and their songs
unique_data <- data %>%
distinct(artist_names, name)
# Write the data frame to a CSV file
write.csv(unique_data, file = "../Data/unique_artists_and_songs.csv", row.names = FALSE)
data <- read.csv("~/Documents/MMMA/MA/Thesis_23/Analysis/Data/data_long_prepped.csv")
# Load the required libraries
library(dplyr)
# Assuming 'data' is your dataset with columns $artist_names and $name
# Create a new data frame with unique artist names and their songs
unique_data <- data %>%
distinct(artist_names, name)
# Write the data frame to a CSV file
write.csv(unique_data, file = "../Data/unique_artists_and_songs.csv", row.names = FALSE)
